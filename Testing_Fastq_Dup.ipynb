{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-06T15:57:04.416053Z",
     "start_time": "2025-03-06T15:57:04.407978Z"
    }
   },
   "source": [
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:18:05.872490Z",
     "start_time": "2025-03-06T16:18:05.866807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def open_fastq(file_path):\n",
    "    \"\"\"Open a FASTQ file, handling both gzipped and uncompressed files.\"\"\"\n",
    "    if file_path.endswith(\".gz\"):\n",
    "        return gzip.open(file_path, \"rt\")  # Open as text mode\n",
    "    else:\n",
    "        return open(file_path, \"r\")  # Open normally"
   ],
   "id": "87b73560620ce39f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:13:34.248118Z",
     "start_time": "2025-03-06T17:13:34.242548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_duplicate_reads(input_fastq, output_fastq):\n",
    "    seen_reads = set() # keeping track of the reads we have observed\n",
    "    duplicate_count = 0  # Track number of duplicates\n",
    "    total_reads = 0  # Track the total number of reads processed\n",
    "    total_size = os.path.getsize(input_fastq)  # Get file size for progress tracking, this does not really work well....\n",
    "\n",
    "    with open_fastq(input_fastq) as infile, open(output_fastq, \"w\") as outfile, tqdm(\n",
    "        total=total_size, unit=\"B\", unit_scale=True, desc=\"Processing Fastq - This bar is probably inaccurate:\" # setting up the progess bar, dosent work well, but at least shows its running....\n",
    "    ) as pbar:\n",
    "        while True:\n",
    "            pos = infile.tell()  # Get current file position for progress tracking\n",
    "            header = infile.readline().strip()\n",
    "            if not header:\n",
    "                break  # End of file\n",
    "\n",
    "            sequence = infile.readline().strip()\n",
    "            plus = infile.readline().strip()\n",
    "            quality = infile.readline().strip()\n",
    "\n",
    "            read_name = header  # Extract read identifier\n",
    "            total_reads += 1  # Increment total reads processed\n",
    "\n",
    "            if read_name not in seen_reads:\n",
    "                seen_reads.add(read_name)\n",
    "                outfile.write(f\"{header}\\n{sequence}\\n{plus}\\n{quality}\\n\")\n",
    "            else:\n",
    "                duplicate_count += 1  # Count duplicates\n",
    "\n",
    "            # Update progress\n",
    "            if input_fastq.endswith(\".gz\"):\n",
    "                pbar.update((len(header) + len(sequence) + len(plus) + len(quality)) / 6)  # Approximate uncompressed progress\n",
    "            else:\n",
    "                pbar.update(infile.tell() - pos)  # Accurate for uncompressed files\n",
    "\n",
    "    # Calculate the percentage of removed reads\n",
    "    if total_reads > 0:\n",
    "        removal_percentage = (duplicate_count / total_reads) * 100\n",
    "    else:\n",
    "        removal_percentage = 0\n",
    "\n",
    "    print(f\"Finished processing. Removed {duplicate_count} duplicate reads.\")\n",
    "    print(f\"Percentage of removed reads: {removal_percentage:.2f}%\")\n"
   ],
   "id": "8485e099e91fbd33",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:56:57.737991Z",
     "start_time": "2025-03-06T16:52:51.079077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing with known problem file (gz)\n",
    "remove_duplicate_reads_new(\"test_data/Cells-Mock-4_R1.fastq.gz\", \"test_data/Cells-Mock-4_dedup_R1.fastq\")"
   ],
   "id": "353f4616ec7aee65",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing FASTQ:  59%|█████▉    | 2.30G/3.87G [04:03<02:46, 9.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Removed 11613199 duplicate reads.\n",
      "Percentage of removed reads: 27.05%\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:03:15.000102Z",
     "start_time": "2025-03-06T17:03:14.881887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing with known good file (non-gz)\n",
    "remove_duplicate_reads_new(\"test_data/test_data.fastq\", \"test_data/test_data_dedup.fastq\")"
   ],
   "id": "278ee4c2a56e20b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing FASTQ: 100%|██████████| 11.2M/11.2M [00:00<00:00, 102MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Removed 0 duplicate reads.\n",
      "Percentage of removed reads: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
